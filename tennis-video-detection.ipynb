{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tennis-video-detection.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Tennis Video Detection : Player, Racket and Ball"
      ],
      "metadata": {
        "id": "_du5l_hkxTLF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing libraries"
      ],
      "metadata": {
        "id": "ijwfVPSzxXZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "metadata": {
        "id": "n59cFkMdxXC2"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connection to Google Drive"
      ],
      "metadata": {
        "id": "2NoQisQ2xhG8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0JaUyWls-Ib",
        "outputId": "31967b49-9925-4eae-8062-2103f3bb3008"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Yolo Model"
      ],
      "metadata": {
        "id": "rh7ky_jlxkD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the network\n",
        "net = cv2.dnn.readNet(\"/content/drive/MyDrive/yolo/yolov3.weights\", \"/content/drive/MyDrive/yolo/yolov3.cfg\")\n",
        "# loading the classes\n",
        "classes = []\n",
        "with open(\"/content/drive/MyDrive/yolo/coco.names\", \"r\") as f:\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "classes[0] = \"tennis player\"\n",
        "# loading layers and colors\n",
        "layer_names = net.getLayerNames()\n",
        "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
        "colors = np.random.uniform(0, 255, size=(len(classes), 3))"
      ],
      "metadata": {
        "id": "S_YBOplTxnWS"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Video"
      ],
      "metadata": {
        "id": "wyamJ8ZsxrDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# specifying video codec\n",
        "fourcc = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "# setting the video output\n",
        "output = cv2.VideoWriter(\"output.mp4\", fourcc , 25, (320, 320))\n",
        "# setting the video input\n",
        "camera = cv2.VideoCapture(\"/content/drive/MyDrive/input_video.mp4\")"
      ],
      "metadata": {
        "id": "jHQ7cM1QxuOv"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Video Detection"
      ],
      "metadata": {
        "id": "y32L5iR0yHQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    # capturing the images on video\n",
        "    _, img = camera.read()\n",
        "    # when no image is captured we stop the loop\n",
        "    if img is None: break\n",
        "    # getting shape informations\n",
        "    img_height, img_width, channels = img.shape\n",
        "\n",
        "    # binary large object of the video\n",
        "    blob = cv2.dnn.blobFromImage(img, 0.00392, (320, 320), (0, 0, 0), True, crop=False)\n",
        "    # putting the video blob on the network\n",
        "    net.setInput(blob)\n",
        "    # saving the outputs of the network\n",
        "    outputs = net.forward(output_layers)\n",
        "\n",
        "    # list of classes index\n",
        "    class_ids = []\n",
        "    # list of classes confidences\n",
        "    confidences = []\n",
        "    # list of classes boxes\n",
        "    boxes = []\n",
        "    # iterating over the detections\n",
        "    for output in outputs:\n",
        "        for detection in output:\n",
        "            # saving the index and the confidence of the detected class\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > 0.5:\n",
        "                # coordinates of the object detected\n",
        "                center_x = int(detection[0] * img_width)\n",
        "                center_y = int(detection[1] * img_height)\n",
        "                width = int(detection[2] * img_width)\n",
        "                height = int(detection[3] * img_height)\n",
        "                # coordinates of the rectangle box \n",
        "                x = int(center_x - width / 2)\n",
        "                y = int(center_y - height / 2)\n",
        "                boxes.append([x, y, width, height])\n",
        "                confidences.append(float(confidence))\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "    # indexs for boxes and classes\n",
        "    indexs = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "\n",
        "    # choosing a font for text\n",
        "    font = cv2.FONT_HERSHEY_PLAIN\n",
        "    # iterating over the boxes\n",
        "    for i in range(len(boxes)):\n",
        "    # verifying if the index is in our list\n",
        "        if i in indexs:\n",
        "            # positions of the box\n",
        "            x, y, w, h = boxes[i]\n",
        "            # name of the class detected\n",
        "            label = str(classes[class_ids[i]])\n",
        "            # color to use for rectangle and text\n",
        "            color = colors[i]\n",
        "            # drawing the rectangle on the image\n",
        "            cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
        "            # writing the text on the image\n",
        "            cv2.putText(img, label, (x, y - 10), font, 1.5, color, 2)\n",
        "    # showing the image\n",
        "    cv2_imshow(img)\n",
        "\n",
        "# closes capturing device\n",
        "camera.release()"
      ],
      "metadata": {
        "id": "St_873FVrvAF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}